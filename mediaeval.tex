\documentclass{acm_proc_article-me11_tweaked}

\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage{upgreek}
\usepackage{bm}


\newcommand{\footremember}[2]{%
   \footnote{#2}
    \newcounter{#1}
    \setcounter{#1}{\value{footnote}}%
}
\newcommand{\footrecall}[1]{%
    \footnotemark[\value{#1}]%
} 

% Tikz
\usepackage{tikz}
\usetikzlibrary{shadows, arrows, positioning, calc, shapes}

\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

\tikzstyle{rect} = [draw = black!50, fill = black!20, very thick, minimum width = 6em, minimum height = 3em, text centered, rounded corners, drop shadow]
\tikzstyle{arrow} = [draw, ultra thick, black!50, -latex']



\newcommand{\backgroundone}[5]{%
	\begin{pgfonlayer}{background}
		% Left-top corner of the background rectangle
		\path (#1.west |- #2.north) + (-1,1) node (a1) {};
		% Right-bottom corner of the background rectanle
		\path (#3.east |- #4.south) + (1,-.5) node (a2) {};
		% Draw the background
		\path [draw=black!50, dashed, ultra thick, fill=black!10, rounded corners] (a1) rectangle (a2);
		% Text at top of the background rectangle
		\path let \p1 = (a1), \p2 = (a2) in node at ($(.5*\x1+.5*\x2,\y1-1em)$) [minimum width = 10em, text width = 20em, text centered] () {\bf #5};
	\end{pgfonlayer}
}

\newcommand{\backgroundtwo}[5]{%
	\begin{pgfonlayer}{background}
		% Left-top corner of the background rectangle
		\path (#1.west |- #2.north) + (-.5,.5) node (a1) {};
		% Right-bottom corner of the background rectanle
		\path (#3.east |- #4.south) + (2.8,-1.) node (a2) {};
		% Draw the background
		\path [draw=black, ultra thick, rounded corners] (a1) rectangle (a2);
		% Text at top of the background rectangle
		\path let \p1 = (a1), \p2 = (a2) in node at ($(.5*\x1+.5*\x2,\y1-1em)$) [minimum width = 10em, text width = 10em, text centered] () {\bf #5};
	\end{pgfonlayer}
}


\begin{document}
\conferenceinfo{\textit{MediaEval 2013 Workshop,}}{October 18-19, 2013, Barcelona, Spain} 

\title{Ghent University-iMinds at MediaEval 2013 Diverse Images: Relevance Based Hierarchical Clustering}

\numberofauthors{5} 
\author{
% 1st. author
\alignauthor
Baptist Vandersmissen$^1$\\
\affaddr{baptist.vandersmissen@ugent.be}\\    
% 2nd. author
\alignauthor
Abineshwar Tomar$^1$ \\
\affaddr{abineshwar.tomar@ugent.be}
% 3rd. author
\alignauthor
Fr\'ederic Godin$^1$\\
\affaddr{frederic.godin@ugent.be}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor
Wesley De Neve$^{1,2}$\\
\affaddr{wesley.deneve@ugent.be}
% 5th. author
\alignauthor
Rik Van de Walle$^1$\\
\affaddr{rik.vandewalle@ugent.be}
\and
% \sharedaffiliation
%       \affaddr{ \email{\texttt{\{baptist.vandersmissen, abineshwar.tomar, frederic.godin, wesley.deneve, rik.vandewalle\}@ugent.be}}}\\
\sharedaffiliation{\affaddr $^1$~ELIS - Multimedia Lab, Ghent University -- iMinds, Ghent, Belgium}\\
\sharedaffiliation{\affaddr $^2$~Image and Video Systems Lab, KAIST, Daejeon, South Korea}\\ 
}
\maketitle
\begin{abstract}
In this paper, we attempt to tackle the MediaEval 2013 Retrieving Diverse Social Images challenge, which is a filter and refinement problem on a Flickr based ranked set of social images.
Three different approaches are developed using respectively only visual data, textual data and a combination of both.
We notice that the combined method gives the overall best results by focusing on textual information for the estimation of relevancy and visual features for assessing the diversity among them.
Hierarchical clustering on highly relevant images followed by complementing the ordering on a greedy way forms the basis of our method.
\end{abstract}
% % A category with the (minimum) three required fields
% \category{H.4}{Information Systems Applications}{Miscellaneous}
% %A category including the fourth, optional field follows...
% \category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
% 
% \terms{Theory}
% 
% \keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings

\section{Introduction}
In this paper, we describe our approach for tackling the MediaEval 2013 Retrieving Diverse Social Images Task \cite{mediaeval-diversephotos}.
This task focuses on result diversification in the context of social image retrieval. 
The goal is to retrieve not only representative but also diverse images that depict the information need in a complete manner.
The requirements of this task are to provide three runs on the test set, respectively focusing on solely visual features, textual features and a combination of both to perform a refinement of the Flickr ranking.
\\\\
We suggest a cluster based approach for the visual run and a textual run based on semantic similarity.
The third run focuses on hierarchical clustering of relevant images and represents a combination of the purely visual and textual techniques.
In the next sections, we will discuss these approaches in more detail.

\section{Visual Run}
\label{visual-similarity}

% Visual run makes use of clustering techniques to increase diversity.
\section{Textual Run}
The textual run solely makes use of information derived from tags and other textual metadata.
This approach aims to diversify the results by reranking the images retrieved from Flickr based on textual relevance and semantic similarity.
Our solution is based on \cite{textual-diversification} and makes use of an adapted performance metric that takes into account both relevance and diversity to evaluate a ranking.
Images for a query can then be ordered by directly optimizing the performance metric.
This metric is named Average Diverse Precision (ADP) and is derived from the conventional Average Precision metric by adding a diversity component.
We refer to \cite{textual-diversification} for a comprehensive overview.
\\\\
Optimizing the expected value of the ADP measurment is a permutation problem of complexity $O(n!)$. 
Therefore a greedy approach that optimizes an estimation of the ADP measurement is implemented. 
Denote by $\pmb\uptau$ an ordering of the images, and let $\uptau(i)$ be the image at the position of rank $i$ (a lower number indicates image with a higher rank).
With the top $ i - 1 $ documents established, we can derive that the $i$th image should be decided as follows
\begin{equation}
 \displaystyle
  \uptau(i) = \text{arg max}_{x \in \mathscr{D} - \mathscr{S} } \frac{Rel(x)}{i} Div(x) ( C + Div(x) ),
\end{equation}
where
\begin{equation}
\mathscr{S} = \left\{\uptau(1), \uptau(2), \ldots , \uptau(i - 1)\right\} ,
\end{equation}
\begin{equation}
C = \sum^{i-1}_{k=1} Rel(\uptau(k)) Div(\uptau(k)).
\end{equation}
Where $Rel(x)$ and $Div(x)$ respectively denote the estimated relevance and diversity of the image.

% $$
% ADP(\pmb \uptau,\mathscr{D}) \stackrel{\Delta}{=}   \frac{1}{R}  \sum^{n}_{j=1}  y\left(\uptau(j)\right) Div\left(\uptau(j)\right)  \left(  \frac{\sum^j_{k=1} y\left(\uptau(k)\right) Div\left(\uptau(k)\right)}{j}  \right)
% $$
%
% The binary relevancy of image $x_i$ with respect to the given query can be denoted as $y(x)$ , i.e. $y(x) = 1$ if $x$ is relevant and otherwise $y(x) = 0$.
% $Div(\uptau(k))$ indicates the diversity score of $\uptau(k)$. Furthermore we define $R$ as being the number of true relevant images in the set of images $\mathscr{D}$, and $n$ the size of the ranking.

\begin{table*}
\centering
\caption{Results on development set (comparison with Flickr) and test set.}
 \begin{tabular}{|r|l|ccl|ccl|ccl|c|}
\cline{2-12}
   \multicolumn{1}{c|}{ } & \multicolumn{5}{c}{\bfseries Development Set (comparison with Flickr)}  & \vrule height2.75ex depth1.25ex width 1pt &  \multicolumn{5}{c|}{\bfseries Test Set} \\\cline{2-12}    
   \multicolumn{1}{c|}{ } & \multicolumn{2}{c}{ + GPS}  & \vrule height2.75ex depth1.25ex width 1pt & \multicolumn{2}{c}{ - GPS} & \vrule height2.75ex depth1.25ex width 1pt & \multicolumn{2}{c}{ + GPS}  & \vrule height2.75ex depth1.25ex width 1pt & \multicolumn{2}{c|}{ - GPS} \\\cline{2-12}
   \multicolumn{1}{c|}{ } &  CR@10 &   P@10 & \vrule height2.75ex depth1.25ex width 1pt &  CR@10 &  P@10 & \vrule height2.75ex depth1.25ex width 1pt &  CR@10 &   P@10 & \vrule height2.75ex depth1.25ex width 1pt &   CR@10 &  P@10 \\
   \hline
   \bfseries Visual   & 43.6  (2.4) & 79.2 (-6.8) & \vrule height2.75ex depth1.25ex width 1pt & 48.4 (2.0)&  71.6 (2.8)& \vrule height2.75ex depth1.25ex width 1pt & 37.5 & 76.1 & \vrule height2.75ex depth1.25ex width 1pt & 34.7 & 56.8\\\hline
  \bfseries Textual  &  44.2  (2.9)  & 81.6 (-4.4) & \vrule height2.75ex depth1.25ex width 1pt & 51.6 (5.2) & 67.2 (-1.6)& \vrule height2.75ex depth1.25ex width 1pt &  39.7  & 74.9 & \vrule height2.75ex depth1.25ex width 1pt & 37.5 & 58.6\\\hline
  \bfseries Combined & \bfseries 49.8  (8.5) & \bfseries 85.6 (-0.4) & \vrule height2.75ex depth1.25ex width 1pt & \bfseries  51.7 (5.3)  & \bfseries 74.8  (6.0)& \vrule height2.75ex depth1.25ex width 1pt  & \bfseries 41.3 & \bfseries 80.5 & \vrule height2.75ex depth1.25ex width 1pt & \bfseries  42.8  & \bfseries 66.7 \\
    \hline
  \end{tabular}
  \label{tbl:results}

  
  
\end{table*} 

\subsection{Relevance Estimation}
\label{text-relevance}
We try to measure the relevancy of an image related to a certain monument.
In order to achieve this we make use of the textual metadata such as number of views, number of comments and social tags.
The task provides this data together with three textual features: TF--IDF, Social TF--IDF and probabilistic model.
We suggest a linear combination of all gathered and normalized data.
$$
Rel(x) = \alpha \times tags_x + \beta \times views_x + \gamma \times comments_x,
$$
where
$$
tags_x = \frac{1}{|\mathscr{T}_x|} \left( \sum_{t \in \mathscr{T}_x} a\times prob_{t,x} + b\times tfidf_{t,x} + c\times stfidf_{t,x}\right), 
$$
is also a linear combination of above described features.
We found that the precision of image orderings, which are purely based on relevance information, can be maximized by setting parameters $a$ and$\gamma$ to be zero and increasing the influence of tags and views.
Thus, implicating that the number of comments and probabilistic model information do not add extra information to the relevance estimation of an image.
% Defining $b = 0.7$, $c = 0.3$ and $\alpha = 0.6$, $\beta = 0.4$ maximizes the precision on the development set.




\subsection{Diversity Estimation}
Diversity of an image is defined as the minimal difference with the other images in the ranking.
$$Div(x) = min_{i \in \{1,\ldots,n\}}\left( 1 - s(x, \uptau(i))\right)$$
We use a semantic similarity measure based on google distance \cite{google-distance} to assess the difference between two images.
The average of the summation of the similarities between the different tags of both images gives us a value that describes the semantic similarity between both images.


\section{Visual and Textual Run}
With the availability of both textual and visual data we can improve above methods.
We use textual data to estimate the relevancy of an image while visual data is used for assessing the similarity.
Next, we give a brief overview of the implemented algorithm.
\subsection{Overview}
To estimate the relevancy of an image we use the textual based method (cf. Section \ref{text-relevance}).
Similarity between images is based on visual image features and a gaussian kernel method to measure the difference between two image vectors (cf. Section \ref{visual-similarity}).
In order to provide both a relevant and diverse ordering we make use of hierarchical clustering techniques.
Assume we want to refine a set of $m$ images retrieved from flickr to a ranking of size $n$.
\begin{itemize}
 \item First, $k$ images are selected with the highest estimated relevancy. $k$ is an arbitrary number that depicts a subset of the final ranking. 
 The larger $k$ becomes the more the focus will shift from relevancy to diversity. Our algorithm sets $k = 10$. Denote that $k$ is a measure for the number of images that is clustered and optimalized for diversity purposes.
%  This step ensures that the ordering will consist mostly out of highly relevant images.
 \item Next, these $k$ images are hierarchically clustered based on a distance matrix calculated with above described visual similarity.
 \item Per cluster the most relevant item is selected and added to the final ranking.
 \item Depending on the number of remaining places of the first $k$ spots in the final ranking images are greedily added based on a \textbf{gain} score.
 This score is higher for images that maximize the diversity and relevancy related to the current ranking.
 \item When the first $k$ spots in the ranking are filled the algorithm starts from the beginning until all $n$ spots are taken.
 
\end{itemize}




\section{Experiments}
To compare our methods we evaluate the created rankings of monuments in the development set based on the delivered ground truth.
We compare the measurements with the regular Flickr rankings to get a general idea of the functioning of our algorithm.
In Table \ref{tbl:results} we can see the results of our created algorithms (three runs) compared to regular Flickr ranking and the results on the test set.
 We notice the superior performance of the combined method over all other methods.



\section{Conclusions}


%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{mediaeval}  % sigproc.bib is the name of the Bibliography in this case


\end{document}
