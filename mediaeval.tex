\documentclass{acm_proc_article-me11_tweaked}

\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage{upgreek}
\usepackage{bm}


\newcommand{\footremember}[2]{%
   \footnote{#2}
    \newcounter{#1}
    \setcounter{#1}{\value{footnote}}%
}
\newcommand{\footrecall}[1]{%
    \footnotemark[\value{#1}]%
} 

% Tikz
\usepackage{tikz}
\usetikzlibrary{shadows, arrows, positioning, calc, shapes}

\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

\tikzstyle{rect} = [draw = black!50, fill = black!20, very thick, minimum width = 6em, minimum height = 3em, text centered, rounded corners, drop shadow]
\tikzstyle{arrow} = [draw, ultra thick, black!50, -latex']



\newcommand{\backgroundone}[5]{%
	\begin{pgfonlayer}{background}
		% Left-top corner of the background rectangle
		\path (#1.west |- #2.north) + (-1,1) node (a1) {};
		% Right-bottom corner of the background rectanle
		\path (#3.east |- #4.south) + (1,-.5) node (a2) {};
		% Draw the background
		\path [draw=black!50, dashed, ultra thick, fill=black!10, rounded corners] (a1) rectangle (a2);
		% Text at top of the background rectangle
		\path let \p1 = (a1), \p2 = (a2) in node at ($(.5*\x1+.5*\x2,\y1-1em)$) [minimum width = 10em, text width = 20em, text centered] () {\bf #5};
	\end{pgfonlayer}
}

\newcommand{\backgroundtwo}[5]{%
	\begin{pgfonlayer}{background}
		% Left-top corner of the background rectangle
		\path (#1.west |- #2.north) + (-.5,.5) node (a1) {};
		% Right-bottom corner of the background rectanle
		\path (#3.east |- #4.south) + (2.8,-1.) node (a2) {};
		% Draw the background
		\path [draw=black, ultra thick, rounded corners] (a1) rectangle (a2);
		% Text at top of the background rectangle
		\path let \p1 = (a1), \p2 = (a2) in node at ($(.5*\x1+.5*\x2,\y1-1em)$) [minimum width = 10em, text width = 10em, text centered] () {\bf #5};
	\end{pgfonlayer}
}


\begin{document}
\conferenceinfo{\textit{MediaEval 2013 Workshop,}}{October 18-19, 2013, Barcelona, Spain} 

\title{Ghent University-iMinds at MediaEval 2013 Diverse Images: Relevance-Based Hierarchical Clustering}

\numberofauthors{5} 
\author{
% 1st. author
Baptist Vandersmissen$^1$\\
\affaddr{baptist.vandersmissen@ugent.be}\\    
% 2nd. author
\alignauthor
Abhineshwar Tomar$^1$ \\
\affaddr{abhineshwar.tomar@ugent.be}
% 3rd. author
\alignauthor
Fr\'ederic Godin$^1$\\
\affaddr{frederic.godin@ugent.be}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor
Wesley De Neve$^{1,2}$\\
\affaddr{wesley.deneve@ugent.be}
% 5th. author
\alignauthor
Rik Van de Walle$^1$\\
\affaddr{rik.vandewalle@ugent.be}
\and
% \sharedaffiliation
%       \affaddr{ \email{\texttt{\{baptist.vandersmissen, abineshwar.tomar, frederic.godin, wesley.deneve, rik.vandewalle\}@ugent.be}}}\\
\sharedaffiliation{\affaddr $^1$~ELIS -- Multimedia Lab, Ghent University -- iMinds, Ghent, Belgium}\\
\sharedaffiliation{\affaddr $^2$~Image and Video Systems Lab, KAIST, Daejeon, South Korea}\\ 
}
\maketitle
\begin{abstract}
In this paper, we attempt to tackle the MediaEval 2013 Retrieving Diverse Social Images challenge, which is a filter and refinement problem on a Flickr-based ranked set of social images.
We developed three different approaches, using visual data, textual data and a combination thereof, respectively.
% We notice that the combined method gives the overall best results by focusing on textual information for the estimation of relevance and visual features for assessing the diversity among them.
Hierarchical clustering on highly relevant images, combined with a greedy approach to complement the ranking, forms the basis of our approach.
\end{abstract}
% % A category with the (minimum) three required fields
% \category{H.4}{Information Systems Applications}{Miscellaneous}
% %A category including the fourth, optional field follows...
% \category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
% 
% \terms{Theory}
% 
% \keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings

\section{Introduction}
In this paper, we describe our approach for tackling the MediaEval 2013 Retrieving Diverse Social Images Task \cite{mediaeval-diversephotos}.
This task focuses on result diversification in the context of social image retrieval. 
The goal is to retrieve not only representative but also diverse images that depict the information need in a complete manner.
The requirements of this task are to provide three runs on the test set, respectively focusing on solely visual features, textual features and a combination of both to perform a refinement of the Flickr ranking.

We suggest a cluster-based approach for the visual run and a semantic similarity-based approach for the textual run.
The third run focuses on hierarchical clustering of relevant images and represents a combination of the purely visual and textual techniques.
In the following sections, we will discuss each of these approaches individually in more detail.

\section{Visual Run}
\label{visual-similarity}
We propose a hierarchical clustering-based approach for the ranking of images in accordance with their relevance and diversity for a specific location \cite{representativeness}. 
% This method tries to tackle the problem of relevance and diversification as a single problem instead of two different problems. 
We want to refine a set of $m$ images retrieved from Flickr to a ranking of size $n$.
\begin{itemize}
 \item The set of $m$ images is hierarchically clustered to produce $k$ clusters. Similarity between two images $x_i$ and $x_j$ is measured using a Gaussian kernel:
 \begin{equation}
 \label{gaussian-similarity}
s(x_i, x_j) = exp\left(-\frac{||x_i - x_j||_2^2}{\sigma^2}\right).
 \end{equation}
 \item For each of the $k$ clusters produced, we calculate a Synthetic Representative Image (SRI) \cite{representativeness}.
The SRI acts as a representative image for all the images within a particular cluster. 
The SRI for a set of images is calculated by taking the mean of all the corresponding feature vectors of these images. 
Intra-cluster ranking of all of the $k$ images is produced by calculating their Euclidean distance to the SRI.
The image with rank 1 (topmost rank) is closest to the SRI of the cluster.
\item Subsequently, we rank the $k$ different clusters by subtracting the cluster SRIs from a general SRI value, which is the mean over all cluster SRIs. 
Finally, $n$ images are selected by iteratively taking the topmost ranked image in the cluster with the highest rank. 
% Final ranking on the images is produced as the combination of the cluster ranking and image ranking within each cluster. 
\end{itemize}

\section{Textual Run}
The textual run makes use of information derived from tags and other textual metadata.
This approach aims at diversifying the results by reranking the images retrieved from Flickr using textual relevance and semantic similarity.
Our solution is based on \cite{textual-diversification} and makes use of an adapted performance metric to improve the ranking characteristics.
Images for a query can then be ordered by directly optimizing the performance metric.
This metric is named Average Diverse Precision (ADP) and is derived from the conventional Average Precision metric by adding a diversity component.
We refer to \cite{textual-diversification} for a comprehensive overview.

% Optimizing the expected value of the ADP measurment is a permutation problem of complexity $O(n!)$. 
We implemented a greedy approach that optimizes an estimation of the ADP measurement. 
Let $\pmb\uptau$ denote an ordering of the images, and let $\uptau(i)$ be the image at the position of rank $i$ (a lower number indicates an image with a higher rank).
With the top $ i - 1 $ documents established, we can derive that the $i$th image should be decided as follows:
\begin{equation}
 \displaystyle
  \uptau(i) = \text{arg max}_{x \in \mathscr{D} - \mathscr{S} } \frac{Rel(x)}{i} Div(x) ( C + Div(x) ),
\end{equation}
where
\begin{equation}
\mathscr{S} = \left\{\uptau(1), \uptau(2), \ldots , \uptau(i - 1)\right\} ,
\end{equation}
\begin{equation}
C = \sum^{i-1}_{k=1} Rel(\uptau(k)) Div(\uptau(k)),
\end{equation}
with $Rel(x)$ and $Div(x)$ denoting the estimated relevance and diversity of the image, respectively.

% $$
% ADP(\pmb \uptau,\mathscr{D}) \stackrel{\Delta}{=}   \frac{1}{R}  \sum^{n}_{j=1}  y\left(\uptau(j)\right) Div\left(\uptau(j)\right)  \left(  \frac{\sum^j_{k=1} y\left(\uptau(k)\right) Div\left(\uptau(k)\right)}{j}  \right)
% $$
%
% The binary relevance of image $x_i$ with respect to the given query can be denoted as $y(x)$ , i.e. $y(x) = 1$ if $x$ is relevant and otherwise $y(x) = 0$.
% $Div(\uptau(k))$ indicates the diversity score of $\uptau(k)$. Furthermore we define $R$ as being the number of true relevant images in the set of images $\mathscr{D}$, and $n$ the size of the ranking.

\begin{table*}
\centering
\caption{Results on development set and test set (in \%). Numbers between brackets denote the relative difference to the Flickr ranking.}
 \begin{tabular}{|r|l|ccl|ccl|ccl|c|}
\cline{2-12}
   \multicolumn{1}{c|}{ } & \multicolumn{5}{c}{\bfseries Development Set (comparison with Flickr)}  & \vrule height2.75ex depth1.25ex width 1pt &  \multicolumn{5}{c|}{\bfseries Test Set} \\\cline{2-12}    
   \multicolumn{1}{c|}{ } & \multicolumn{2}{c}{ + GPS}  & \vrule height2.75ex depth1.25ex width 1pt & \multicolumn{2}{c}{ - GPS} & \vrule height2.75ex depth1.25ex width 1pt & \multicolumn{2}{c}{ + GPS}  & \vrule height2.75ex depth1.25ex width 1pt & \multicolumn{2}{c|}{ - GPS} \\\cline{2-12}
   \multicolumn{1}{c|}{ } &  \textit{CR@10} &   \textit{P@10} & \vrule height2.75ex depth1.25ex width 1pt &  \textit{CR@10} &  \textit{P@10} & \vrule height2.75ex depth1.25ex width 1pt &  \textit{CR@10} &   \textit{P@10} & \vrule height2.75ex depth1.25ex width 1pt &   \textit{CR@10} & \textit{P@10} \\
   \hline
   \bfseries Visual   & 43.6  (2.4) & 79.2 (-6.8) & \vrule height2.75ex depth1.25ex width 1pt & 48.4 (2.0)&  71.6 (2.8)& \vrule height2.75ex depth1.25ex width 1pt & 37.5 & 76.1 & \vrule height2.75ex depth1.25ex width 1pt & 34.7 & 56.8\\\hline
  \bfseries Textual  &  44.2  (2.9)  & 81.6 (-4.4) & \vrule height2.75ex depth1.25ex width 1pt & 51.6 (5.2) & 67.2 (-1.6)& \vrule height2.75ex depth1.25ex width 1pt &  39.7  & 74.9 & \vrule height2.75ex depth1.25ex width 1pt & 37.5 & 58.6\\\hline
  \bfseries Combined & \bfseries 49.8  (8.5) & \bfseries 85.6 (-0.4) & \vrule height2.75ex depth1.25ex width 1pt & \bfseries  51.7 (5.3)  & \bfseries 74.8  (6.0)& \vrule height2.75ex depth1.25ex width 1pt  & \bfseries 41.3 & \bfseries 80.5 & \vrule height2.75ex depth1.25ex width 1pt & \bfseries  42.8  & \bfseries 66.7 \\
    \hline
  \end{tabular}
  \label{tbl:results}

  
  
\end{table*} 

\subsection{Relevance Estimation}
\label{text-relevance}
% We try to measure the relevance of an image related to a certain information need.
We estimate the relevance of an image by making use of textual metadata (number of views, number of comments) and social tags.
This data was provided together with three textual features: TF--IDF, Social TF--IDF and a probabilistic feature type.
We suggest a linear combination of this normalized data.
\begin{equation}
Rel(x) = \alpha \times tags_x + \beta \times views_x + \gamma \times comments_x,
\end{equation}
where
\begin{equation}
tags_x = \frac{ \sum_{t \in \mathscr{T}_x} a\text{ prob}_{t,x} + b\text{ tfidf}_{t,x} + c\text{ stfidf}_{t,x}}{|\mathscr{T}_x|} , 
\end{equation}
with $\mathscr{T}_x$ denoting the set of tags linked to image $x$.
% is also a linear combination of above described features.
We found that the precision of image orderings, which are purely based on relevance information, can be maximized by setting parameters $a$ and $\gamma$ to zero and increasing the impact of the parameters linked to 'tag' and 'views' information.
% Thus, implicating that the number of comments and probabilistic model information do not add extra information to the relevance estimation of an image.
% Defining $b = 0.7$, $c = 0.3$ and $\alpha = 0.6$, $\beta = 0.4$ maximizes the precision on the development set.




\subsection{Diversity Estimation}
Diversity of an image to a ranking is defined as the minimal difference with the other images in that ranking:
\begin{equation}
 Div(x) = min_{i \in \{1,\ldots,n\}}\left( 1 - s(x, \uptau(i))\right)
\end{equation}

We use a semantic similarity measure based on Google distance \cite{google-distance} to assess the difference between two images.
The average of the summation of the similarities between the different tags of both images gives us a value that describes the semantic similarity between both images.


\section{Visual and Textual Run}
With the availability of both textual and visual data, we can improve the above methods.
% We use textual data to estimate the relevance of an image while visual data is used for assessing the similarity.
% Next, we give a brief overview of the implemented algorithm.
% \subsection{Overview}
To estimate the relevance of an image, we use the textual-based method (cf. Section \ref{text-relevance}).
Similarity between images is based on visual image features and a Gaussian kernel method to measure the difference between two image vectors (cf. Equation \ref{gaussian-similarity}).
In order to provide both a relevant and diverse ordering, we make use of hierarchical clustering techniques.
We, again, try to refine a set of $m$ images retrieved from Flickr to a ranking of size $n$.
\begin{itemize}
 \item First, $l$ images are selected with the highest estimated relevance. $l$ is an arbitrary number that depicts a subset of the final ranking. 
The larger $l$ becomes, the more the focus will shift from relevance to diversity. 
%  Denote that $l$ is a measure for the number of images that is clustered and optimalized for diversity purposes.
%  This step ensures that the ordering will consist mostly out of highly relevant images.
 \item Next, these $l$ images are hierarchically clustered based on a distance matrix calculated with the above described visual similarity.
 \item Per cluster, the most relevant item is selected and added to the final ranking.
 \item Depending on the number of remaining places of the first $l$ spots in the final ranking, images are greedily added based on a \textbf{gain} score.
 This score is higher for images that maximize the diversity and relevance related to the current ranking.
 \item When the first $l$ spots in the ranking are filled, the algorithm starts from the beginning until all $n$ spots are taken.
 
\end{itemize}




\section{Experiments}
To compare our methods, we refine the rankings of all locations in the development set and evaluate them with the delivered ground truth.
% We compare the measurements with the regular Flickr rankings to get a general idea of the functioning of our algorithm.
In Table \ref{tbl:results}, we can see the results of our algorithms (three runs), compared to the regular Flickr ranking and the results on the test set.
We notice that the combined method creates the most precise and diverse rankings based on both precision and cluster recall measures compared to the other developed methods (averages 42.1\% cluster recall on test set). 
% The precision of the image orderings is heavily based on the used data to retrieve images from Flickr. 
% Results on the test set show a cluster recall of around 42\% for the best method.
Image sets retrieved based on GPS data have by default a high precision, thus making it harder to improve in that area.

%  When not using GPS data to retrieve images linked to a certain monument results are more scattered resulting in a 'accidental' higher cluster recall.   

\section{Conclusions}
We observe that a method clustering images focused on high relevance outperforms all others.
This method uses textual data for the relevance estimation and visual features for the diversity assessment.
% Retrieving both diverse and relevant images involves the accurate ana
For future work, we plan to incorporate tag refinement in order to to enhance the relevance estimation. In addition, we plan to incorporate textual data in the diversity estimation.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{mediaeval}  % sigproc.bib is the name of the Bibliography in this case


\end{document}

